[project]
name = "k-eval"
version = "0.1.0"
description = "Context-aware evaluation framework for AI agents using MCP."
readme = "README.md"
license = "Apache-2.0"
requires-python = ">=3.13"
authors = [
    { name = "jsell-rh" },
]
keywords = ["evaluation", "ai", "agents", "mcp", "llm"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.13",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Software Development :: Testing",
]

dependencies = [
    "claude-agent-sdk>=0.1.39",
    "litellm",
    "pydantic>=2.12.5",
    "pyyaml>=6.0.3",
    "rich>=14.3.3",
    "structlog>=25.5.0",
    "typer>=0.24.1",
]

[project.urls]
Homepage = "https://github.com/jsell-rh/k-eval"
Repository = "https://github.com/jsell-rh/k-eval"
Issues = "https://github.com/jsell-rh/k-eval/issues"

[project.scripts]
k-eval = "k_eval.cli.main:app"

[project.optional-dependencies]
vertex_ai = ["google-cloud-aiplatform>=1.138.0"]
all = ["k-eval[vertex_ai]"]

[dependency-groups]
dev = [
    "mypy>=1.19.1",
    "pytest>=9.0.2",
    "pytest-asyncio>=1.3.0",
    "ruff>=0.15.2",
    "types-pyyaml>=6.0.12.20250915",
]

[tool.setuptools.packages.find]
where = ["."]
include = ["k_eval*"]

[tool.pytest.ini_options]
pythonpath = ["."]
testpaths = ["tests"]

asyncio_mode = "auto"

[tool.ruff]
target-version = "py313"

[tool.mypy]
python_version = "3.13"
strict = true
mypy_path = "."
packages = ["k_eval"]
