{
  "schema_version": "0.2.1",
  "evaluation_id": "ca83991f-9443-4fe8-aa89-3dd126c84477",
  "retrieved_timestamp": "1772039646",
  "source_metadata": {
    "source_name": "k-eval",
    "source_type": "evaluation_run",
    "source_organization_name": "k-eval",
    "evaluator_relationship": "self"
  },
  "model_info": {
    "id": "claude-sonnet-4-5",
    "name": "claude-sonnet-4-5",
    "developer": null,
    "inference_platform": null
  },
  "eval_library": {
    "name": "k-eval",
    "version": "dev"
  },
  "evaluation_results": [
    {
      "evaluation_name": "kartograph-graph-context-eval/baseline",
      "evaluation_timestamp": "1772039646",
      "source_data": {
        "source_type": "jsonl_file",
        "dataset_sha256": "75b18f4c607990ee22a208bbc5104e30c734264fbe45018f847877754110ded0",
        "samples_number": 52
      },
      "metric_config": {
        "evaluation_description": "k-eval LLM-as-judge scoring: factual_adherence, completeness, helpfulness_and_clarity (each 1-5)",
        "lower_is_better": false,
        "score_type": "composite",
        "min_score": 1.0,
        "max_score": 5.0
      },
      "score_details": {
        "score": null,
        "details": {
          "factual_adherence_mean": 2.967948717948718,
          "factual_adherence_stddev": 0.2301856752808248,
          "completeness_mean": 2.423076923076923,
          "completeness_stddev": 0.177646236673731,
          "helpfulness_and_clarity_mean": 4.038461538461538,
          "helpfulness_and_clarity_stddev": 0.1554404570895146
        }
      },
      "generation_config": {
        "judge_temperature": 0.0
      }
    },
    {
      "evaluation_name": "kartograph-graph-context-eval/with_graph",
      "evaluation_timestamp": "1772039646",
      "source_data": {
        "source_type": "jsonl_file",
        "dataset_sha256": "75b18f4c607990ee22a208bbc5104e30c734264fbe45018f847877754110ded0",
        "samples_number": 52
      },
      "metric_config": {
        "evaluation_description": "k-eval LLM-as-judge scoring: factual_adherence, completeness, helpfulness_and_clarity (each 1-5)",
        "lower_is_better": false,
        "score_type": "composite",
        "min_score": 1.0,
        "max_score": 5.0
      },
      "score_details": {
        "score": null,
        "details": {
          "factual_adherence_mean": 3.3846153846153846,
          "factual_adherence_stddev": 0.2968030140334739,
          "completeness_mean": 2.948717948717949,
          "completeness_stddev": 0.3493424526405677,
          "helpfulness_and_clarity_mean": 4.378205128205128,
          "helpfulness_and_clarity_stddev": 0.22205779584216373
        }
      },
      "generation_config": {
        "judge_temperature": 0.0
      }
    }
  ],
  "detailed_evaluation_results": {
    "file_path": "kartograph-graph-context-eval_20260225_ca83991f.detailed.jsonl",
    "format": "jsonl",
    "checksum": "75b18f4c607990ee22a208bbc5104e30c734264fbe45018f847877754110ded0"
  }
}